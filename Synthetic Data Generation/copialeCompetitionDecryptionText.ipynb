{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Match the Copiale competition images to their decryptions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file does the following tasks:\n",
    "- Map new manuscript image names to old names, these old names contain the page and line number of the original manuscript\n",
    "- Find the equivalent decryption of these lines in the according .txt file for the deciphered manuscript\n",
    "- Add these decryptions to the manuscript json file unifying: transcription, decryption and copiale font translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import re\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "def parse_manuscript_file(txt_file_path: str) -> Dict[int, List[str]]:\n",
    "    \"\"\"\n",
    "    Parse the deciphered manuscript text file and organize lines by page number.\n",
    "    \n",
    "    Args:\n",
    "        txt_file_path: Path to the manuscript .txt file\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with page numbers as keys and lists of lines as values\n",
    "    \"\"\"\n",
    "    pages = {}\n",
    "    current_page = None\n",
    "    \n",
    "    with open(txt_file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.rstrip('\\n\\r')\n",
    "            \n",
    "            # Check for page marker (e.g., \"## PAGE 57\")\n",
    "            page_match = re.match(r'##\\s*PAGE\\s+(\\d+)', line.strip())\n",
    "            if page_match:\n",
    "                current_page = int(page_match.group(1))\n",
    "                pages[current_page] = []\n",
    "                continue\n",
    "            \n",
    "            # Skip empty lines and lines with just \"#\"\n",
    "            if not line.strip() or line.strip() == '#':\n",
    "                continue\n",
    "                \n",
    "            # Add line to current page if we have one\n",
    "            if current_page is not None:\n",
    "                pages[current_page].append(line.strip())\n",
    "    \n",
    "    return pages\n",
    "\n",
    "def load_csv_mapping(csv_file_path: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Load the CSV file that maps new image names to old names.\n",
    "    \n",
    "    Args:\n",
    "        csv_file_path: Path to the CSV mapping file\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping new names to old names\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    \n",
    "    with open(csv_file_path, 'r', encoding='utf-8') as file:\n",
    "        # Try to detect the CSV format\n",
    "        sample = file.read(1024)\n",
    "        file.seek(0)\n",
    "        \n",
    "        # Check if it has headers\n",
    "        sniffer = csv.Sniffer()\n",
    "        has_header = sniffer.has_header(sample)\n",
    "        \n",
    "        reader = csv.reader(file)\n",
    "        \n",
    "        if has_header:\n",
    "            headers = next(reader)\n",
    "            # Find the column indices for new_name and old_name\n",
    "            new_name_idx = None\n",
    "            old_name_idx = None\n",
    "            \n",
    "            for i, header in enumerate(headers):\n",
    "                if 'new' in header.lower() and 'name' in header.lower():\n",
    "                    new_name_idx = i\n",
    "                elif 'old' in header.lower() and 'name' in header.lower():\n",
    "                    old_name_idx = i\n",
    "            \n",
    "            if new_name_idx is None or old_name_idx is None:\n",
    "                print(\"Warning: Could not find 'new_name' and 'old_name' columns in headers\")\n",
    "                print(f\"Headers found: {headers}\")\n",
    "                # Assume first two columns are new_name, old_name\n",
    "                new_name_idx, old_name_idx = 0, 1\n",
    "        else:\n",
    "            # Assume first two columns are new_name, old_name\n",
    "            new_name_idx, old_name_idx = 0, 1\n",
    "        \n",
    "        for row in reader:\n",
    "            if len(row) > max(new_name_idx, old_name_idx):\n",
    "                new_name = row[new_name_idx].strip()\n",
    "                old_name = row[old_name_idx].strip()\n",
    "                \n",
    "                # Ensure new_name has .png extension\n",
    "                if not new_name.endswith('.png'):\n",
    "                    new_name += '.png'\n",
    "                    \n",
    "                mapping[new_name] = old_name\n",
    "    \n",
    "    return mapping\n",
    "\n",
    "def parse_old_name(old_name: str) -> Optional[tuple]:\n",
    "    \"\"\"\n",
    "    Parse the old name format (e.g., \"58_12\") to extract page and line numbers.\n",
    "    \n",
    "    Args:\n",
    "        old_name: String in format \"page_line\"\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (page_number, line_number) or None if parsing fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parts = old_name.split('_')\n",
    "        if len(parts) == 2:\n",
    "            page_num = int(parts[0])\n",
    "            line_num = int(parts[1])\n",
    "            return page_num, line_num\n",
    "    except (ValueError, IndexError):\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def get_line_from_page(pages: Dict[int, List[str]], page_num: int, line_num: int) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Get a specific line from a specific page.\n",
    "    \n",
    "    Args:\n",
    "        pages: Dictionary of pages and their lines\n",
    "        page_num: Page number\n",
    "        line_num: Line number (0-indexed)\n",
    "        \n",
    "    Returns:\n",
    "        The line text or None if not found\n",
    "    \"\"\"\n",
    "    if page_num not in pages:\n",
    "        return None\n",
    "    \n",
    "    page_lines = pages[page_num]\n",
    "    if 0 <= line_num < len(page_lines):\n",
    "        return page_lines[line_num]\n",
    "    \n",
    "    return None\n",
    "\n",
    "def add_plaintext_to_json(json_file_path: str, csv_file_path: str, txt_file_path: str, output_file_path: str):\n",
    "    \"\"\"\n",
    "    Main function to add plaintext to the JSON file.\n",
    "    \n",
    "    Args:\n",
    "        json_file_path: Path to the existing JSON file\n",
    "        csv_file_path: Path to the CSV mapping file\n",
    "        txt_file_path: Path to the manuscript text file\n",
    "        output_file_path: Path where to save the updated JSON\n",
    "    \"\"\"\n",
    "    print(\"Loading and parsing files...\")\n",
    "    \n",
    "    # Load existing JSON\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Parse manuscript pages\n",
    "    pages = parse_manuscript_file(txt_file_path)\n",
    "    print(f\"Parsed {len(pages)} pages from manuscript\")\n",
    "    \n",
    "    # Load CSV mapping\n",
    "    mapping = load_csv_mapping(csv_file_path)\n",
    "    print(f\"Loaded {len(mapping)} mappings from CSV\")\n",
    "    \n",
    "    # Process each image in the JSON\n",
    "    processed_count = 0\n",
    "    missing_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    for image_name in data.keys():\n",
    "        if image_name in mapping:\n",
    "            old_name = mapping[image_name]\n",
    "            parsed = parse_old_name(old_name)\n",
    "            \n",
    "            if parsed:\n",
    "                page_num, line_num = parsed\n",
    "                plaintext = get_line_from_page(pages, page_num, line_num)\n",
    "                \n",
    "                if plaintext is not None:\n",
    "                    data[image_name]['plaintext'] = plaintext\n",
    "                    processed_count += 1\n",
    "                else:\n",
    "                    print(f\"Warning: Could not find line {line_num} on page {page_num} for {image_name}\")\n",
    "                    missing_count += 1\n",
    "            else:\n",
    "                print(f\"Error: Could not parse old_name '{old_name}' for {image_name}\")\n",
    "                error_count += 1\n",
    "        else:\n",
    "            print(f\"Warning: No mapping found for {image_name}\")\n",
    "            missing_count += 1\n",
    "    \n",
    "    # Save updated JSON\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nProcessing complete!\")\n",
    "    print(f\"Successfully processed: {processed_count}\")\n",
    "    print(f\"Missing/not found: {missing_count}\")\n",
    "    print(f\"Errors: {error_count}\")\n",
    "    print(f\"Updated JSON saved to: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and parsing files...\n",
      "Parsed 105 pages from manuscript\n",
      "Loaded 4985 mappings from CSV\n",
      "Warning: Could not find line 17 on page 58 for T2_0101.png\n",
      "Warning: Could not find line 17 on page 60 for T2_0540.png\n",
      "Warning: Could not find line 17 on page 56 for T2_0741.png\n",
      "Warning: Could not find line 17 on page 88 for T2_0917.png\n",
      "Warning: Could not find line 17 on page 74 for T2_0950.png\n",
      "Warning: Could not find line 17 on page 12 for T2_1107.png\n",
      "Warning: Could not find line 17 on page 100 for T2_1200.png\n",
      "Warning: Could not find line 17 on page 54 for T2_1429.png\n",
      "Warning: Could not find line 16 on page 99 for T2_1453.png\n",
      "\n",
      "Processing complete!\n",
      "Successfully processed: 1493\n",
      "Missing/not found: 9\n",
      "Errors: 0\n",
      "Updated JSON saved to: /home/moliveros/Datasets/copialeManuscriptWithDecryption/copiale_dataset_with_decryption.json\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Example usage of the script.\n",
    "    Update the file paths below to match your actual files.\n",
    "    \"\"\"\n",
    "    # File paths - update these to match your actual file locations\n",
    "    json_file_path = \"/home/moliveros/Datasets/copialeManuscript/copiale_dataset.json\"  # Your existing JSON file\n",
    "    csv_file_path = \"/home/moliveros/Datasets/copiale-decryptedText/task2_names.csv\"   # Your CSV mapping file\n",
    "    txt_file_path = \"/home/moliveros/Datasets/copiale-deciphered.txt\"  # Your manuscript text file\n",
    "    output_file_path = \"/home/moliveros/Datasets/copialeManuscriptWithDecryption/copiale_dataset_with_decryption.json\"  # Output file\n",
    "    \n",
    "    try:\n",
    "        add_plaintext_to_json(json_file_path, csv_file_path, txt_file_path, output_file_path)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: File not found - {e}\")\n",
    "        print(\"Please update the file paths in the main() function to match your actual files.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvc2.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
